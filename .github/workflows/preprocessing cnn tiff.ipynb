{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Lung Cancer CNN\"\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs\\\\{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"F://DB3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\"Benign\", \"Malignant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in CATEGORIES: \n",
    "    path = os.path.join(DATADIR,category)  # create path to benign or malignant\n",
    "    for img in os.listdir(path):  # iterate over each image per data\n",
    "        img_array = cv2.imread(os.path.join(path,img))  # convert to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4165/4165 [00:01<00:00, 3118.44it/s]\n",
      "100%|██████████| 2526/2526 [00:00<00:00, 2898.04it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:  \n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path \n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1)\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [255, 247, 249, ...,   0,   0,   0],\n",
       "        [255, 253, 255, ...,   0,   0,   0],\n",
       "        [250, 255, 252, ...,   0,   0,   0]], dtype=uint8), 1]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X = np.array(X).reshape(-1, IMG_SIZE,IMG_SIZE, 1)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6691, 64, 64, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4683 samples, validate on 2008 samples\n",
      "Epoch 1/10\n",
      "   6/4683 [..............................] - ETA: 25:00 - loss: 0.6366 - accuracy: 0.8333WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.171873). Check your callbacks.\n",
      "4683/4683 [==============================] - 50s 11ms/sample - loss: 0.5862 - accuracy: 0.7049 - val_loss: 0.5190 - val_accuracy: 0.7465\n",
      "Epoch 2/10\n",
      "4683/4683 [==============================] - 48s 10ms/sample - loss: 0.4598 - accuracy: 0.7826 - val_loss: 0.4923 - val_accuracy: 0.7809\n",
      "Epoch 3/10\n",
      "4683/4683 [==============================] - 47s 10ms/sample - loss: 0.3910 - accuracy: 0.8198 - val_loss: 0.4782 - val_accuracy: 0.7844\n",
      "Epoch 4/10\n",
      "4683/4683 [==============================] - 49s 10ms/sample - loss: 0.3215 - accuracy: 0.8629 - val_loss: 0.4818 - val_accuracy: 0.7804\n",
      "Epoch 5/10\n",
      "4683/4683 [==============================] - 43s 9ms/sample - loss: 0.2502 - accuracy: 0.8922 - val_loss: 0.5177 - val_accuracy: 0.7829\n",
      "Epoch 6/10\n",
      "4683/4683 [==============================] - 43s 9ms/sample - loss: 0.2000 - accuracy: 0.9169 - val_loss: 0.5792 - val_accuracy: 0.7903\n",
      "Epoch 7/10\n",
      "4683/4683 [==============================] - 45s 10ms/sample - loss: 0.1472 - accuracy: 0.9404 - val_loss: 0.7500 - val_accuracy: 0.7878\n",
      "Epoch 8/10\n",
      "4683/4683 [==============================] - 44s 9ms/sample - loss: 0.1312 - accuracy: 0.9462 - val_loss: 0.8024 - val_accuracy: 0.7864\n",
      "Epoch 9/10\n",
      "4683/4683 [==============================] - 44s 9ms/sample - loss: 0.1122 - accuracy: 0.9537 - val_loss: 0.9651 - val_accuracy: 0.7789\n",
      "Epoch 10/10\n",
      "4683/4683 [==============================] - 45s 10ms/sample - loss: 0.0921 - accuracy: 0.9622 - val_loss: 1.0263 - val_accuracy: 0.7968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f80ce5f0c8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X/255.0\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=3, input_shape = (64,64,1)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss = \"binary_crossentropy\",\n",
    "             optimizer = \"adam\",\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X,y, batch_size = 6, epochs = 10, validation_split = 0.3, callbacks = [tensorboard])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
